```mermaid
flowchart LR
    A((UsuÃ¡rio)) -->|Entra com Prompt/Comando| B[/ChatCLI/]
    B -->|Verifica comando interno| C{Command Handler?}
    C -->|Sim| D(Executar comando interno)
    D --> B
    C -->|NÃ£o| E[Processa prompt normal]
    E -->|Chama| F(LLM Manager)
    F -->|Verifica configuraÃ§Ã£o| G{Provedor?}
    G -->|OpenAI| H[OpenAI Client]
    G -->|Claude| I[Claude Client]
    G -->|StackSpot| J[StackSpot Client]
        
    H --> K[Resposta LLM]
    I --> K
    J -->|Gerencia Token| K
        
    K -->|Retorna| B
    B -->|Renderiza Output| A
```

# ChatCLI - Arquitetura

## 1. VisÃ£o Geral do Funcionamento

- **ChatCLI** Ã© uma aplicaÃ§Ã£o de linha de comando (CLI) que interage com diversos modelos de linguagem (LLMs) â€” StackSpot, OpenAI e ClaudeAI.
- O usuÃ¡rio digita comandos ou mensagens diretamente no terminal, e as solicitaÃ§Ãµes sÃ£o enviadas para um dos provedores de LLM configurados.
- HÃ¡ comandos especiais (`@history`, `@git`, `@env`, `@file`, `@command`, etc.) que adicionam contexto adicional ao prompt antes do envio para a IA.
- **Fluxo principal:**
    1. O usuÃ¡rio digita algo na CLI.
    2. O ChatCLI processa se Ã© um comando especial (ex.: `@file`) ou um comando interno (`/exit`, `/switch` etc.).
    3. Envia-se a requisiÃ§Ã£o ao LLM atravÃ©s de um cliente especializado (`OpenAIClient`, `StackSpotClient` ou `ClaudeClient`).
    4. Recebe-se a resposta e a exibe com formataÃ§Ã£o Markdown, possÃ­vel animaÃ§Ã£o de "pensando...", etc.

## 2. Estrutura de Pastas

```
chatcli/
â”‚â”€â”€ cli/
â”‚   â”œâ”€â”€ cli.go
â”‚   â”œâ”€â”€ animation_manager.go
â”‚   â”œâ”€â”€ command_handler.go
â”‚   â”œâ”€â”€ command_handler_test.go
â”‚   â”œâ”€â”€ history_manager.go
â”‚
â”‚â”€â”€ llm/
â”‚   â”œâ”€â”€ openai/
â”‚   â”œâ”€â”€ claudeai/
â”‚   â”œâ”€â”€ stackspotai/
â”‚   â”œâ”€â”€ manager/
â”‚   â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ token/
â”‚
â”‚â”€â”€ config/
â”‚
â”‚â”€â”€ models/
â”‚
â”‚â”€â”€ utils/
â”‚   â”œâ”€â”€ file_utils.go
â”‚   â”œâ”€â”€ git_utils.go
â”‚   â”œâ”€â”€ shell_utils.go
â”‚   â”œâ”€â”€ logging_transport.go
â”‚   â”œâ”€â”€ http_client.go
â”‚   â”œâ”€â”€ path.go
â”‚   â”œâ”€â”€ utils.go
â”‚
â”‚â”€â”€ main.go
```

### 2.1 **DescriÃ§Ã£o das Pastas**

#### `cli/` - Interface de Linha de Comando
- `cli.go`: Classe principal ChatCLI que gerencia o loop de entrada de usuÃ¡rio, animaÃ§Ãµes e chamadas para LLMs.
- `animation_manager.go`: Gerencia a animaÃ§Ã£o de â€œPensandoâ€¦â€ usando goroutines.
- `command_handler.go`: Processa os comandos `/exit`, `/switch`, `/reload` e direciona a execuÃ§Ã£o.
- `history_manager.go`: Gerencia o arquivo `.chatcli_history`, salva e carrega o histÃ³rico entre sessÃµes.

#### `llm/` - Camada de AbstraÃ§Ã£o dos Modelos de Linguagem
- **Subpastas:** `openai/`, `claudeai/`, `stackspotai/` â†’ Cada uma com sua implementaÃ§Ã£o de cliente.
- `manager/`: Gerencia qual cliente LLM serÃ¡ usado.
- `client/`: Interface `LLMClient` e mocks para testes.
- `token/`: Gerencia tokens de acesso (por exemplo, StackSpot ou OAuth).

#### `config/` - ConfiguraÃ§Ã£o
- Armazena valores padrÃ£o, como modelos default, URLs de API, tamanhos mÃ¡ximos de log ou histÃ³rico.

#### `models/` - Modelos de Dados
- `Message`: Representa mensagens trocadas.
- `ResponseData`: Status e resposta.

#### `utils/` - FunÃ§Ãµes UtilitÃ¡rias
- `file_utils.go`: ManipulaÃ§Ã£o de arquivos.
- `git_utils.go`: InteraÃ§Ã£o com Git.
- `shell_utils.go`: HistÃ³rico de shells (`bash`, `zsh`, `fish`).
- `logging_transport.go`: Logs de requests HTTP.
- `http_client.go`: Cliente HTTP customizado.
- `path.go`: ManipulaÃ§Ã£o de caminhos.
- `utils.go`: Helpers diversos (`UUID`, carregamento de `.env`).

#### `main.go` - Ponto de Entrada
- Carrega `.env`, inicializa logger, verifica provedores e inicia a CLI.

## 3. Fluxo LÃ³gico em Resumo

1. `main.go` carrega `.env` (se existir), configura o logger e checa variÃ¡veis essenciais (`CLIENT_ID`, `OPENAI_API_KEY`, etc.).
2. Cria-se o `LLMManager`, que define o provedor de IA (`OPENAI`, `STACKSPOT`, `CLAUDEAI`, etc.).
3. `ChatCLI` lÃª comandos em loop:
    - `/exit`: Sai.
    - `/switch`: Troca de provedor.
    - `/reload`: Recarrega `.env`.
    - `/help`: Exibe ajuda.
    - `@history`, `@env`, `@file`: Adicionam contexto ao prompt.
    - `@command`: Executa comandos no shell do usuÃ¡rio.
    - Caso contrÃ¡rio, envia a mensagem ao LLM e exibe a resposta.
4. HistÃ³rico de inputs do usuÃ¡rio salvo em `.chatcli_history`.
5. Ao encerrar, faz um shutdown gracioso, fecha o logger e libera recursos.

## 4. CaracterÃ­sticas de Desempenho e Arquitetura

### Uso de Goroutines
- `AnimationManager`: roda animaÃ§Ãµes em paralelo sem bloquear requisiÃ§Ãµes.
- `@file`: usa `workers` (4 goroutines) para leitura simultÃ¢nea de arquivos.

### TolerÃ¢ncia a Falhas e Retry
- `OpenAIClient`, `ClaudeClient`, `StackSpotClient`: Implementam **retry** com **backoff exponencial**.

### Compatibilidade com Shells
- Suporte para `bash`, `zsh`, `fish`.

### Logging Extensivo
- `LoggingTransport`: registra requisiÃ§Ãµes HTTP (sanitiza tokens/senhas).
- **RotaÃ§Ã£o de logs** configurÃ¡vel via `lumberjack`.

### ConfiguraÃ§Ãµes via ENV
- Tudo Ã© configurÃ¡vel por variÃ¡veis de ambiente (`provedores`, `modelo`, `chave de API`, etc.).

## 5. PossÃ­veis Melhorias

- **Uso intensivo de variÃ¡veis de ambiente**: Pode ser refinado para maior seguranÃ§a em produÃ§Ã£o.
- **Granularidade de retry**: Configurar melhor a estratÃ©gia de re-tentativa por tipo de erro.
- **Testes mais robustos**: Expandir mocks e adicionar testes de integraÃ§Ã£o.
- **HistÃ³rico persistente**: Implementar uma forma de salvar conversas de forma mais estruturada.
- **Gerenciamento de arquivos**: Melhorar eficiÃªncia na leitura de arquivos grandes.

## 6. ConclusÃ£o

- `cli/` gerencia a **interface de linha de comando**.
- `llm/` abstrai mÃºltiplos **provedores de IA**.
- `utils/` contÃ©m **funÃ§Ãµes auxiliares**.
- **ConfiguraÃ§Ã£o** baseada em `.env`, com **suporte a mÃºltiplos shells** e **execuÃ§Ã£o de comandos nativa**.
- **ExtensÃ­vel**, **leve** e com **boas prÃ¡ticas de desenvolvimento** aplicadas.

ğŸš€ **ChatCLI oferece uma experiÃªncia fluida para acessar LLMs diretamente do terminal!**

